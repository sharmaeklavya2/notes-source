\documentclass[a4paper, 12pt, fleqn]{article}

\usepackage{amsmath,amsthm,amssymb}
\usepackage[margin=1in]{geometry}
\usepackage{xcolor}
\usepackage{array}
\usepackage{comment}
\usepackage{booktabs}
\usepackage[bookmarksnumbered=true,hypertexnames=false]{hyperref}
%\usepackage{algorithm, algpseudocode}
\usepackage[capitalize,sort]{cleveref}

%\def\colorscheme{dark}
\input{colorscheme.tex}
\hypersetup{colorlinks,linkcolor=textRed,citecolor=textRed,urlcolor=textBlue}
\input{macros.tex}

\DeclareMathOperator{\boolone}{\mathbf{1}}

\author{Eklavya Sharma}
\date{\empty}

\title{Stochastic Processes}

\begin{document}

\maketitle
\setlength{\parskip}{0.2em}

\begin{definition}[Stochastic Process]
Let $\Tcal \subseteq \mathbb{R}$. For any $t \in \Tcal$,
let $X_t$ (or $X(t)$) be a random variable with support $D$.
Then $X \defeq \{X_t: t \in \Tcal\}$ is called a
\emph{stochastic process} on state-space $D$ and time $\Tcal$.
Usually, $\Tcal$ is either $\mathbb{Z}_{\ge 0}$ (discrete-time)
or $\mathbb{R}_{\ge 0}$ (continuous-time).
\end{definition}

\section{Discrete-Time Markov Chains}

\begin{definition}[Markov Chain]
Let $X \defeq [X_0, X_1, \ldots]$ be a stochastic process
on state-space $D$ and time $\mathbb{Z}_{\ge 0}$.
$X$ is called a discrete-time markov chain if
$\Pr(X_{t+1}=d \mid X_t, X_{t-1}, \ldots, X_0) = \Pr(X_{t+1}=d \mid X_t)$.
If $\Pr(X_{t+1}=d \mid X_t) = \Pr(X_1=d \mid X_0)$, then $X$ is called \emph{time-homogeneous}.
\end{definition}

\begin{definition}[Transition function]
Let $X$ be a markov chain on state space $D$.
Define $P^{(k)}: D \times D \mapsto [0, 1]$ as $P^{(k)}(i, j) = \Pr(X_k = j \mid X_0 = i)$.
Then $P^{(k)}$ is called the $k$-step transition function of $X$.
For $k = 1$, we simply write $P$ instead of $P^{(1)}$.
For a finite state space, we can represent $P$ as a matrix.
\end{definition}

\begin{lemma}[Chapman-Kolmogorov Equation]
$P^{(m+n)}(i, j) = \sum_{k}P^{(m)}(i, k)P^{(n)}(k, j)$.
\end{lemma}

\subsection{Classification of States, Recurrence, Limiting Probabilities}

\begin{definition}
Let $f_{i,j} \defeq \Pr\left(\bigvee_{t \ge 1} (X_t = j) \Bigm| X_0 = i\right)$.
Then $f_{i,j}$ is called the \emph{eventual transition probability} from $i$ to $j$.
If $i = j$, then we write $f_{i,i}$ as $f_i$, and call it
the \emph{recurrence probability} of state $i$.
\end{definition}

\begin{definition}
For a state $i$, let $N_i$ be the random variable that counts the number of times
we are in state $i$, i.e., $N_i \defeq \sum_{t=0}^{\infty}\boolone(X_t = i)$.
Then $N_i$ is called the visit-count of $i$.
\end{definition}

\begin{definition}
A state $i$ of a markov chain is \emph{recurrent} iff (the following are equivalent):
\begin{itemize}
\item the recurrence probability ($f_i$) of $i$ is 1.
\item $i$ is visited infinitely often, i.e., $\Pr(N_i=\infty \mid X_0 = i) = 1$.
\item $i$ is visited infinitely often in expectation, i.e., $\E(N_i \mid X_0 = i) = \infty$.
\end{itemize}
A non-recurrent state is called a \emph{transient} state.
\end{definition}

\begin{lemma}
$\Pr(N_i = k \mid X_0 = i) = f_i^{k-1}(1-f_i)$.
\end{lemma}

\begin{lemma}
$\E(N_i \mid X_0 = i) = 1/(1-f_i) = \sum_{t=0}^{\infty}P^{(t)}(i,i)$.
\end{lemma}

\begin{definition}
State $j$ is \emph{accessible} from state $i$ if $P^{(t)}(i, j) > 0$ for some $t$.
States $i$ and $j$ \emph{communicate} (denoted as $i \leftrightarrow j$)
if $i$ and $j$ are both accessible from each other.
\end{definition}

\begin{lemma}
Accessibility is reflexive and transitive.
Communication is an equivalence relation.
The equivalence classes of communicability are called \emph{state classes}.
A markov chain is \emph{irreducible} if it has just one state class.
\end{lemma}

\begin{definition}
Let $T_i$ be the time when a markov chain moves to state $i$, i.e.,
$T_i \defeq \min_{t \ge 1} (X_t = i)$.
When conditioned on $X_0 = i$, $T_i$ is called the \emph{recurrence time} of $i$.
State $i$ is called \emph{positive recurrent} if $\E(T_i \mid X_0=i)$ is finite,
otherwise it is \emph{null recurrent}.
\end{definition}

\begin{lemma}
Recurrence and positive recurrence are class properties, i.e.,
they are same for all states in a class.
\end{lemma}

\begin{lemma}
In a finite-state markov chain, all recurrent states are positive recurrent,
and there is at least one recurrent state.
\end{lemma}

\begin{definition}[Periodicity]
For a state $i$, its period is defined as $\gcd(\{t: \Pr(T_i=t \mid X_0=i) > 0\})$.
A state is \emph{aperiodic} if its period is 1.
\end{definition}

\begin{lemma}
Periodicity is a class property.
\end{lemma}

\begin{definition}[Ergodicity]
A state is ergodic if it is positive recurrent and aperiodic.
A markov chain is ergodic if all its states are ergodic.
\end{definition}

\begin{lemma}
In an irreducible ergodic markov chain, for every state $j$,
$\lim_{t \to \infty} P^{(t)}(j, i) = \pi_i$ for a unique real number $\pi_i$.
$\pi_i$ is called the \emph{limiting probability} of state $i$.
Furthermore, $\pi_i$ is the unique solution to
this system of equations: $\pi_i = \sum_{j} \pi_j P(j, i)$ for all $i$
($\pi = P^T\pi$ in matrix form) and $\sum_i \pi_i = 1$.
\end{lemma}

\begin{lemma}
In an irreducible ergodic markov chain, $\E(T_i \mid X_0=i) = 1/\pi_i$.
\end{lemma}
\begin{corollary}
A state $i$ is null recurrent iff $\pi_i = 0$.
\end{corollary}

\begin{theorem}
If the transition function of markov chain $X$ is doubly-stochastic
(i.e., each row and each column sums to 1), then the limiting probability
of each state is $1/n$, where $n$ is the number of states.
\end{theorem}

\subsection{Time-Reversibility}

\begin{definition}
For an irreducible ergodic markov chain $X$ with limiting probabilities $\pi$.
Let $Y$ be a markov chain whose transition function is $Q(i, j) = P(j, i)(\pi_j/\pi_i)$.
Then $Y$ is called the \emph{time-reversed} markov chain of $X$.
$X$ is called \emph{time-reversible} if $Q = P$.
\end{definition}

\begin{theorem}
Let $X$ be a time-reversible markov chain with limiting probabilities $\pi$.
Then $\pi$ is the unique solution to this system of equations:
$x_jP(j, i) = x_iP(i, j)$ for all states $i$ and $j$, and $\sum_i x_i = 1$.
\end{theorem}

\begin{theorem}
If the transition function of markov chain $X$ is symmetric, then $X$ is time-reversible.
\end{theorem}

\section{Counting Process}

\begin{definition}[Counting Process]
Let $N$ be a stochastic process on state space $\mathbb{Z}_{\ge 0}$ and time $\mathbb{R}_{\ge 0}$.
Then $N$ is called a counting process if $N(0) = 0$ and $N(t)$ is monotone in $t$,
i.e., $t_1 < t_2 \implies N(t_1) \le N(t_2)$.
\end{definition}

\begin{definition}[Independent increments]
A counting process $N$ has \emph{independent increments} iff
for any two disjoint intervals $(u_1, v_1]$ and $(u_2, v_2]$ in $\mathbb{R}_{\ge 0}$,
the random variables $N(v_1) - N(u_1)$ and $N(v_2) - N(u_2)$ are independent.
\end{definition}

\begin{definition}[Stationary increments]
A counting process $N$ has \emph{stationary increments} iff for any $u \le v$,
the random variables $N(v) - N(u)$ and $N(v-u)$ have the same distribution.
\end{definition}

\section{Poisson Process}

\begin{definition}[Poisson process]
A counting process $N$ is a Poisson process with rate $\lambda$ if
$N$ has independent and stationary increments and $N(t) \sim \opname{Poisson}(\lambda t)$.
\end{definition}

\end{document}
